## Page 1.
Hello everyone, welcome to my presentation at Iros 2024. My name is Kaichen Zhou, and today I will be discussing our paper, SCANet. This work primarily investigates and explores how to correct components that encounter errors during the assembly process. This is an area that has not been previously addressed, making our research pioneering. Additionally, we have developed a dataset specifically for the error correction task, along with a baseline method.
## Page 2.
First, let’s discuss the motivation behind our work. We have observed that existing assembly methods have a certain probability of incorrectly assembling components during the process. As the assembly task progresses, these errors can accumulate, leading to a final assembly result that deviates significantly from the expected outcome. While humans also make mistakes during assembly, they possess a correction mechanism that allows them to identify and rectify previous errors throughout the process. In contrast, current assembly methods completely overlook this correction aspect, focusing solely on completing the assembly task. Therefore, we believe it is essential to integrate self-correction into robots for long horizontal tasks.
## Page 3.
Building on our motivation, we introduce a new task: Single-Step Assembly Error Correction. This task focuses on inspecting and correcting the components assembled at time T. For instance, if three components were assembled in the 12th step, our goal is to evaluate only those three components and rectify any assembly errors. To support this task, we have developed a dataset called the LEGO Error Correction Assembly Dataset. Finally, we propose a baseline model, the Self-Correct Assembly Network, to effectively address the single-step assembly error correction task.
During our initial exploration, we discovered that multi-step assembly error correction is significantly more challenging than single-step correction. Therefore, we wanted to start with the simpler task of single-step correction before gradually exploring multi-step assembly error correction.
## Page 4.
We define this task in two parts: First is the normal assembly process, where inputs include the assembly manual diagram, the initial shape (the result of the previous step), and the components for the current step. The goal is to assemble these components onto the initial shape, ensuring the result matches the manual diagram. The second part is the assembly correction process, where inputs include the resulting shape after assembly, a 2D rendering, the components used, and their 6D pose data. The model must identify whether each component is correctly assembled and provide the correct 6D pose for any misassembled parts.
## Page 5.
In this work, we constructed the LEGO-ECA dataset, which is based on the Synthetic LEGO Dataset. We randomly selected 1,429 assembly manuals and added examples of assembly errors to each step within these manuals. For each assembly error example, we annotated the type of error and its correct assembly pose. In total, this dataset contains approximately 120,000 assembly error examples.
To ensure the stable and diverse generation of erroneous assembly examples during the dataset construction, we introduced varying levels of Gaussian noise to the manual images before inputting them into the assembly model. This interference allows us to obtain a rich variety of assembly error examples.
## Page 6.
Here is an example from our dataset. The first row displays the assembly manual image, the second row shows the corresponding possible error examples, the third row presents the associated shape, and the fourth row provides information about the components with assembly errors.
## Page 7.
Next, let’s introduce our method. We start by considering the question: How do humans perform assembly error correction? We have broken down the human error correction process into four steps:
First, humans observe the assembly result to identify any errors.
Next, they compare the assembly result with the assembly manual to check for discrepancies.
If differences are found, they analyze which components were incorrectly assembled and determine the correct positions for those components.
Finally, humans correct the errors in the improperly assembled components.
These steps outline how humans approach error correction, and our method draws inspiration from this process to a certain extent.
## Page 8.
Based on the observations and analysis before, we propose the Self-Correct Assembly Network. The core idea of this method is to treat each assembled component as a query. This allows us to query the assembly manual image to verify whether these components are correctly assembled, and if they are not, to determine their correct pose.
The overall architecture of our method is inspired by the DETR model and consists of two main modules: the CNN Backbone and the Assembly Correction Module. The CNN Backbone is primarily responsible for identifying and comparing discrepancies between the assembled result and the assembly manual image. Meanwhile, the Assembly Correction Module focuses on analyzing and correcting the erroneous components.
## Page 9.
The CNN Backbone consists of two input branches for the assembly manual image and assembled result data, sharing parameters and identical structures. The outputs are concatenated and fed into a difference extractor that compresses the dimensions from 512 to 256 to extract difference features. The Assembly Correction Module has three parts: the Component Pose Encoder, Transformer Network, and Component Pose Corrector. The Component Pose Encoder processes components with their 6D pose information, unlike the simpler CNN Backbone encoder. The Transformer Network encodes the difference features, which are queried by the encoded component features in the decoder. Finally, the Component Pose Corrector determines if each component is correctly assembled and, if errors are detected, outputs the correct pose.
## Page 10.
The Component Pose Encoder in the Assembly Correction Module includes three sub-encoders: the 3D Voxel Encoder, 6D Pose Encoder, and 2D Image Encoder. The 3D Voxel Encoder uses 3D convolutions, batch normalization, and ReLU activation to convert voxel data into a one-dimensional feature vector. The 6D Pose Encoder uses fully connected layers to transform pose data into a feature vector, which is then summed with the voxel features. The 2D Image Encoder, based on ResNet, processes the image data, and its output is concatenated with the summed vector, producing the final encoded component features. Combining both geometric and color information is crucial because encoding only geometric data leads SCANet to correct components with identical shapes to the same pose, while encoding only color lacks geometric context, reducing performance.
## Page 11.
The Component Pose Corrector has three parts: the Component State Classifier, 3D Position Correction Head, and Rotation Correction Head, all using fully connected layers. The Component State Classifier identifies the component's state as correctly assembled, position error, rotation error, or both. The 3D Position Correction Head is inspired by the SimCC network, which estimates human poses by projecting coordinates onto XY axes and classifying them to reduce computational costs. We adapted this for 3D space. Lastly, the Rotation Correction Head is based on MEPNet, which limits the rotation direction of components to four values, treating it as a classification task.
## Page 12.
Our experimental results show that SCANet significantly improves MEPNet's assembly correction, with consistent performance across both familiar and unseen datasets. Ablation studies highlight the importance of SCANet’s architecture. Modifying MEPNet for assembly correction improves accuracy but falls short of SCANet's performance. Removing the assembly result branch slightly reduces accuracy, showing the need for both branches. Excluding the 2D image encoder from the pose encoder leads to a noticeable drop in performance, confirming its critical role. Eliminating the 6D pose encoder causes a drastic performance decline, worse than the original MEPNet, emphasizing its importance. A confusion matrix also verifies SCANet’s accuracy in identifying component assembly states and errors.
## Page 13
Here we present the visualization results of assembly correction before and after using SCANet. In the visualizations, the red boxes indicate components with errors prior to correction, while the green boxes represent successfully corrected components. From the figures, it is clear that SCANet effectively achieves the goal of assembly correction.
Additionally, we observed that, despite SCANet's capabilities, it cannot guarantee 100% error correction. This leads to the phenomenon of error accumulation, represented by the blue boxes in the images. Even in situations that SCANet has never encountered during training, it can still perform error correction, further demonstrating the robustness of SCANet.
## Page 14.
In conclusion, we introduce the “Single-Step Assembly Error Correction Task” to address errors in component assembly, supported by the LEGO-ECA dataset based on Synthetic LEGO data. We propose SCANet, a novel framework designed to tackle this task, aiming to improve automated assembly processes. For future work, exploring a more effective correction mechanism is crucial. One approach is to adopt an iterative correction process, rather than correcting all errors in a single step. Another is to consider multi-step error correction, focusing not only on components at time T but also on earlier errors by using a correction window.
## Page 15. 
Thank you for your attention.

